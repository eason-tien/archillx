# ArcHillx v1.0.0 — Model Routing Rules
# Format: "provider:model_id"
# Providers: anthropic / openai / google / groq / mistral / ollama / custom

# ── Default model ────────────────────────────────────────────────────────────
default: "anthropic:claude-sonnet-4-6"

# ── Task-type rules ──────────────────────────────────────────────────────────
# First matching rule wins.
task_type_rules:
  - match: ["code_exec", "code_review", "coding"]
    model: "anthropic:claude-sonnet-4-6"
    max_tokens: 4096

  - match: ["web_search", "research", "summarize"]
    model: "openai:gpt-4o-mini"
    max_tokens: 4096

  - match: ["analysis", "reasoning", "planning"]
    model: "anthropic:claude-sonnet-4-6"
    max_tokens: 4096

  - match: ["creative", "writing"]
    model: "anthropic:claude-sonnet-4-6"
    max_tokens: 4096

  - match: ["translation", "general"]
    model: "anthropic:claude-sonnet-4-6"
    max_tokens: 2048

# ── Budget rules ─────────────────────────────────────────────────────────────
budget_rules:
  - budget: "low"
    model: "groq:llama-3.1-8b-instant"

  - budget: "medium"
    model: "anthropic:claude-sonnet-4-6"

  - budget: "high"
    model: "anthropic:claude-opus-4-6"

# ── Fallback chain ────────────────────────────────────────────────────────────
# If the primary model fails, try these in order.
fallback_chain:
  - "anthropic:claude-sonnet-4-6"
  - "openai:gpt-4o-mini"
  - "groq:llama-3.3-70b-versatile"
  - "google:gemini-2.0-flash"
  - "mistral:mistral-small-latest"
  - "ollama:llama3.2"

# ── Extra providers (optional) ────────────────────────────────────────────────
# These will be initialised from env vars if not already set via .env.
# providers:
#   my_custom_provider:
#     base_url: "https://my-api.example.com/v1"
#     api_key: "sk-..."
